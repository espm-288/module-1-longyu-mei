---
title: "Module 1: Tabular Data"
subtitle: "Working with larger-than-RAM data using duckdbfs"
author: "ESPM 288"
format: html
---

## Introduction

In this module, we will explore high-performance workflows for tabular data. We will use `duckdbfs` to work with datasets that are larger than available RAM by leveraging DuckDB's streaming and remote file access capabilities.

## Case Study: Global Supply Chains

We will be working with [EXIOBASE 3.8.1](https://source.coop/youssef-harby/exiobase-3), a global Multi-Regional Input-Output (MRIO) database. This dataset tracks economic transactions between sectors and regions, along with their environmental impacts (emissions, resource use, etc.).

**Data description:**
- **Coverage**: 44 countries + 5 rest-of-world regions.
- **Timeframe**: 1995â€“2022.
- **Content**: Economic transactions (Z matrix), final demand (Y matrix), and environmental stressors (F matrix).
- **Format**: Cloud-optimized Parquet, partitioned by year and matrix type.

## Setup

```{r}
# Install ggplot2 if not already installed
if (!require("ggplot2", quietly = TRUE)) {
    install.packages("ggplot2", repos = "https://cloud.r-project.org")
}

library(duckdbfs)
library(dplyr)
library(ggplot2)

```

## Exercise 1: connecting to remote data

We can open the entire dataset without downloading it using `open_dataset()`. The data is hosted on Source Cooperative. The `**` pattern allows recursive scanning of the partitioned parquet files.

```{r}
# Remote S3 path to EXIOBASE 3 (Source Cooperative)

duckdbfs::duckdb_secrets(
    key = "",
    secret = "",
    endpoint = "s3.amazonaws.com",
    region = "us-west-2"
)
s3_url <- "s3://us-west-2.opendata.source.coop/youssef-harby/exiobase-3/4588235/parquet/**"

# Open the dataset lazily
exio <- open_dataset(s3_url)

# View the schema (column names and types) without reading data
glimpse(exio)
```

I want to identify data on the CO2 production country by country over time.

First let's see what tables are available in the dataset:

```{r}
exio|>
    distinct(matrix) |>
    collect()
```

Open the F_satellite table only in the data, and give me unique values for the stressor column:
```{r}
exio|>
    filter(matrix == "F_satellite") |>
    distinct(stressor) |>
    collect()

```

There's a lot of possible stressor types, how can I find the ones that are just about CO2(carbon dioxide emissions)?

```{r}
exio|>
    filter(matrix == "F_satellite",
           stressor %like% "%CO2%") |>
    filter(grepl("CO2|carbon dioxide", stressor, ignore.case = TRUE)) |>
    distinct(stressor) |>
    collect()
```
Identify which regions are the top 5 CO2 emitters:
```{r}
# Get top 5 CO2 emitting regions across all years
top_co2_regions <- exio |>
    filter(matrix == "F_satellite",
           stressor %like% "%CO2%") |>
    group_by(region) |>
    summarise(total_co2 = sum(value, na.rm = TRUE),
              unit = first(unit)) |>
    arrange(desc(total_co2)) |>
    head(5) |>
    collect()

top_co2_regions
```


Export all unique stressor types from F_matrix to a markdown file:
```{r}
# Get all unique stressor types from F_satellite
stressors <- exio |>
    filter(matrix == "F_satellite") |>
    distinct(stressor) |>
    collect()

# Write to markdown file
writeLines(
    c("# F_satellite Stressor Types",
      "",
      paste("Total unique stressors:", nrow(stressors)),
      "",
      "## List of Stressors",
      "",
      paste("-", stressors$stressor)),
    "stressor_types.md"
)

cat("Exported", nrow(stressors), "stressor types to stressor_types.md\n")
```

## Exercise 2: Efficient Filtering

The dataset is large. We should filter *before* collecting any data into R.

```{r}
exio |>
    filter(year == 2022, region == "US") |>
    head() |> # view the first 6 rows
    collect()
```

> **Task**: Construct a query to find the top 5 sectors in the US by CO2 emissions in 2022. Remember to check the column names in `exio` to find the appropriate emissions flow.

```{r}
# Query CO2 emissions data from F_satellite matrix
co2_data <- exio |>
    filter(year == 2022, 
           region == "US",
           matrix == "F_satellite",
           stressor %like% "%CO2%") |>
    group_by(sector) |>
    summarise(total_co2 = sum(value, na.rm = TRUE),
              unit = first(unit)) |>
    arrange(desc(total_co2)) |>
    head(5) |>
    collect()

co2_data
```

## Exercise 3: Comprehensive CO2 Analysis

Now let's read in all CO2 data for further analysis.

```{r}
# Read all CO2 emissions by region for 2022
co2_by_region <- exio |>
    filter(year == 2022,
           matrix == "F_satellite",
           stressor %like% "%CO2%") |>
    group_by(region) |>
    summarise(total_co2 = sum(value, na.rm = TRUE),
              unit = first(unit)) |>
    arrange(desc(total_co2)) |>
    collect()

# View top 20 CO2 emitters
head(co2_by_region, 20)
```

## Exercise 4: Visualizing CO2 Emissions Over Time

```{r}
# Identify top 5 CO2 emitters (based on 2022 data)
top5_emitters <- co2_by_region |>
    head(5) |>
    pull(region)

top5_emitters
```

```{r}
# Get time series for top 5 emitters
co2_timeseries_top5 <- exio |>
    filter(matrix == "F_satellite",
           stressor %like% "%CO2%",
           region %in% top5_emitters) |>
    group_by(year, region) |>
    summarise(total_co2 = sum(value, na.rm = TRUE)) |>
    arrange(year, region) |>
    collect()

co2_timeseries_top5
```

```{r}
# Visualize CO2 emissions over time for top 5 emitters
library(ggplot2)

plot_co2 <- ggplot(co2_timeseries_top5, aes(x = year, y = total_co2, color = region, group = region)) +
    geom_line(linewidth = 1.2) +
    geom_point(size = 2) +
    labs(title = "CO2 Emissions Over Time: Top 5 Emitters (1995-2022)",
         x = "Year",
         y = "Total CO2 Emissions",
         color = "Country/Region") +
    theme_minimal() +
    theme(legend.position = "bottom",
          plot.title = element_text(hjust = 0.5, face = "bold"))

# Display the plot
print(plot_co2)

# Save the plot to a file you can open
ggsave("co2_emissions_top5.png", plot = plot_co2, width = 10, height = 6, dpi = 300)
```
